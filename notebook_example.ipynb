{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "081c1d34",
   "metadata": {},
   "source": [
    "# Narnian DEMO\n",
    "\n",
    "## Table of contents\n",
    "1. [Download Repo](#download-repo)\n",
    "2. [Install Dependencies](#install-dependencies)\n",
    "3. [1st example](#1st-example)\n",
    "4. [2nd example](#2nd-example)\n",
    "5. [3rd example](#3rd-example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ecc9c9",
   "metadata": {},
   "source": [
    "### Download Repo <a name=\"download-repo\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce97b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "oauth_token = input(\"Insert github oauth token: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d37feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%git clone https://{oauth_token}@github.com/mela64/narnian.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38e8ca0",
   "metadata": {},
   "source": [
    "### Install Dependencies <a name=\"install-dependencies\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e81aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd narnian/\n",
    "%pip install -r -q requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c05ae-a5a0-4603-9c75-b6b6b2ffd93a",
   "metadata": {},
   "source": [
    "### Load Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931f21f2-5357-49ee-9b3e-2a9e48e08a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from narnian.model import Model\n",
    "from narnian.attributes import Attributes\n",
    "from modules.networks import PredRNN\n",
    "from modules.networks import GenCTBEInitStateBZeroInput, GenRNN, set_seed\n",
    "from narnian.server import Server\n",
    "from narnian.streams import Stream\n",
    "from narnian.model import EmptyModel\n",
    "from basic.basic_agent import BasicAgent\n",
    "from basic.basic_streams import Sin, Square\n",
    "from basic.basic_environment import BasicEnvironment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16aefb",
   "metadata": {},
   "source": [
    "### Define the Models used in the Demo\n",
    "\n",
    "Demo models consists practically of a **generator** and a **predictor**:\n",
    "- Generator: in this case, we have 2 kinds of generators: \n",
    "    - `GenRNN`: A simple rnn model (**DemoModel1**).\n",
    "    - `GenCTBE..`: An antysimmetric rnn with Exact Matrix Exponential Blocks (**DemoModel2**).\n",
    "- Predictor: We will have a case with and without the predictor:\n",
    "    - `None`: For this model no predictor is defined (**DemoModel1**).\n",
    "    - `PredRNN`: A simple rnn model (**DemoModel2**).\n",
    "\n",
    "Along the models definition, DemoModel includes also the `learn` method which, in this specific case, it is implemented as a common GD training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa0ec4e-c812-4168-8339-ff8dc0f07fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemoModel1(Model):\n",
    "\n",
    "    def __init__(self, attributes: list[Attributes], lr: float = 0.0001, device: torch.device = torch.device(\"cpu\"), seed: int = 0):\n",
    "        \"\"\"Creates a model composed of a generator and a predictor.\"\"\"\n",
    "        \n",
    "        # getting shape info from attributes (it is needed to build the generator/predictor)\n",
    "        assert len(attributes) == 2, \"Only two attributes are supported/expected (about y and d)\"\n",
    "        u_shape = attributes[0].shape\n",
    "        d_dim = attributes[1].shape.numel()\n",
    "        y_dim = attributes[0].shape.numel()\n",
    "        \n",
    "        set_seed(seed)\n",
    "        generator = GenRNN(u_shape=u_shape, d_dim=d_dim, y_dim=y_dim, h_dim=150)\n",
    "        # generator = GenCTBEInitStateBZeroInput(u_shape=u_shape, d_dim=d_dim, y_dim=y_dim, h_dim=150, delta=0.1,\n",
    "        #                                        local=True, cnu_memories=0)\n",
    "        predictor = None\n",
    "\n",
    "        # creating the model (superclass)\n",
    "        super(DemoModel1, self).__init__(generator, predictor, attributes, device=device)\n",
    "\n",
    "        # extra stuff\n",
    "        self.optim = torch.optim.SGD(list(self.generator.parameters()), lr=lr)\n",
    "        self.loss_gen = torch.nn.functional.mse_loss\n",
    "        self.loss_pred = torch.nn.functional.mse_loss\n",
    "\n",
    "    def learn(self,\n",
    "              y: torch.Tensor | None, yhat: torch.Tensor | None,\n",
    "              d: torch.Tensor | None, dhat: torch.Tensor | None) \\\n",
    "            -> tuple[float, torch.Tensor | None, torch.Tensor | None, torch.Tensor | None, torch.Tensor | None]:\n",
    "        \"\"\"Learn from different types of data (some of them could be None).\"\"\"\n",
    "\n",
    "        # clean arguments, ensuring that what should be forced to None is actually forced to None\n",
    "        _, y, yhat, d, dhat = super().learn(y, yhat, d, dhat)  # it seems unuseful, but IT MUST be called!\n",
    "\n",
    "        # evaluating loss function\n",
    "        loss = ((self.loss_gen(y, yhat) if yhat is not None else 0.) +\n",
    "                (self.loss_pred(d, dhat) if dhat is not None else 0.))\n",
    "\n",
    "        # learning\n",
    "        self.optim.zero_grad()\n",
    "        loss_as_float = loss.item()\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "\n",
    "        return loss_as_float, y, yhat, d, dhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemoModel2(Model):\n",
    "\n",
    "    def __init__(self, attributes: list[Attributes], lr: float = 0.0001, device: torch.device = torch.device(\"cpu\")):\n",
    "        \"\"\"Creates a model composed of a generator and a predictor.\"\"\"\n",
    "\n",
    "        # getting shape info from attributes (it is needed to build the generator/predictor)\n",
    "        assert len(attributes) == 2, \"Only two attributes are supported/expected (about y and d)\"\n",
    "        u_shape = attributes[0].shape\n",
    "        d_dim = attributes[1].shape.numel()\n",
    "        y_dim = attributes[0].shape.numel()\n",
    "        set_seed(seed)\n",
    "        \n",
    "        generator = GenCTBEInitStateBZeroInput(u_shape=u_shape, d_dim=d_dim, y_dim=y_dim, h_dim=500, delta=0.1,\n",
    "                                               local=False, cnu_memories=0)\n",
    "        predictor = PredRNN(y_dim=y_dim, d_dim=d_dim, h_dim=10)\n",
    "\n",
    "        # creating the model (superclass)\n",
    "        super(DemoModel2, self).__init__(generator, predictor, attributes, device=device)\n",
    "\n",
    "        # extra stuff\n",
    "        self.optim = torch.optim.SGD(list(self.generator.parameters()) + list(self.predictor.parameters()), lr=lr)\n",
    "        self.loss_gen = torch.nn.functional.mse_loss\n",
    "        self.loss_pred = torch.nn.functional.mse_loss\n",
    "\n",
    "    def learn(self,\n",
    "              y: torch.Tensor | None, yhat: torch.Tensor | None,\n",
    "              d: torch.Tensor | None, dhat: torch.Tensor | None) \\\n",
    "            -> tuple[float, torch.Tensor | None, torch.Tensor | None, torch.Tensor | None, torch.Tensor | None]:\n",
    "        \"\"\"Learn from different types of data (some of them could be None).\"\"\"\n",
    "\n",
    "        # clean arguments, ensuring that what should be forced to None is actually forced to None\n",
    "        _, y, yhat, d, dhat = super().learn(y, yhat, d, dhat)  # it seems unuseful, but IT MUST be called!\n",
    "\n",
    "        # evaluating loss function\n",
    "        loss = ((self.loss_gen(y, yhat) if yhat is not None else 0.) +\n",
    "                (self.loss_pred(d, dhat) if dhat is not None else 0.))\n",
    "\n",
    "        # learning\n",
    "        self.optim.zero_grad()\n",
    "        loss_as_float = loss.item()\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "\n",
    "        return loss_as_float, y, yhat, d, dhat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac253bee-5d78-4268-8a85-21a8b775691a",
   "metadata": {},
   "source": [
    "## Demo 1: Simple Teacher-Student with one stream to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af7821b",
   "metadata": {},
   "source": [
    "We decided to name it 'env' with a certain title 'Demo Sandbox Signal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac8ff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating environment\n",
    "env = BasicEnvironment(\"env\", title=\"Demo Sandbox Signal\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53a4ae0",
   "metadata": {},
   "source": [
    "Then we define a new stream which is a sin wave. \n",
    "A stream is characterized by a name, the source where the stream is coming from (the enviroment in this case), the stream itself ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96088b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.add_stream(Stream.create(name=\"sin\", creator=env.name, stream=Sin(freq=0.06, phase=0.5, delta=0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ad351",
   "metadata": {},
   "source": [
    "Now it's time for defining the FSMs for the agents and the enviroment.\n",
    "Lets start with the FSM of the enviroment...\n",
    "\n",
    "What we want is to:\n",
    "  1. Moving from the init state to letting the streams of the enviroment enabled.\n",
    "  2. Since the streams are enabled, we can now letting all the agents know that such streams are available.\n",
    "  3. The enviroment will then move to the 'ready' state, making all the agents knowing each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa2b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling behaviour of the environment\n",
    "env.add_transit(\"init\", \"streams_enabled\", action=\"enable_all_streams\")\n",
    "env.add_transit(\"streams_enabled\", \"streams_sent\", action=\"send_streams_to_all\")\n",
    "env.add_transit(\"streams_sent\", \"ready\", action=\"send_agents_to_all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41e0a2d",
   "metadata": {},
   "source": [
    "#### Now we can define the Teacher agent\n",
    "\n",
    "We define the agent that will act the role of the Teacher in this demo.\n",
    "\n",
    "Since each agent is characterized by a name, a model and its autority within the environment, we can now define the teacher agent as follows:\n",
    "- Name: 'Teacher'\n",
    "- Model: A dummy model \n",
    "- Authority: 1 (the highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e41905",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = BasicAgent(\"Teacher\", model=EmptyModel(), authority=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8492ebf",
   "metadata": {},
   "source": [
    "Define the FSM of the teacher agent...\n",
    "\n",
    "What we want is to:\n",
    "  1. Let the teacher agent know that the streams are now available. (init -> got_streams) _Rember that in the enviroment FSM we have enabled the streams_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04128136",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag.add_transit(\"init\", \"got_streams\", action=\"get_streams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bef6b54",
   "metadata": {},
   "source": [
    "  2. The teacher, after knowing the streams, is waiting for knowing the other agents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "265c4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag.add_transit(\"got_streams\", \"got_agents\", action=\"get_agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8da0f0c",
   "metadata": {},
   "source": [
    "  3. The teacher, after knowing the other agents, is ready to record the streams flowing in the enviroment.\n",
    "\n",
    "To identify the streams, we can use the `stram_hash` attribute, in this specific case the associated hash is \"env:sin\"\n",
    "We decide to record 2000 samples of the stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de19afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag.add_transit(\"got_agents\", \"recording1\", action=\"record\", args={\"stream_hash\": env.name + \":sin\", \"steps\": 2000})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9528f99",
   "metadata": {},
   "source": [
    "The teacher, after recording the streams, start to find for agents to engage.\n",
    "_(Since this action does not imply any change in the FSM, we add a state action with the state recording1)_\n",
    "\n",
    "`min_auth` and the `max_auth` are set to 0.0, meaning that we are waiting for agent with autority strictly equal to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f36c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag.add_state_action(\"recording1\", action=\"find_agent_to_engage\", args={\"min_auth\": 0.0, \"max_auth\": 0.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4455cb74",
   "metadata": {},
   "source": [
    "  4. When students are found the teacher starts an engagement with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2791fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag.add_transit(\"recording1\", \"student_found\", action=\"send_engagement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fea856",
   "metadata": {},
   "source": [
    "5. All the students which answer with a positive feedback are then engaged in the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8433f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag.add_transit(\"student_found\", \"student_engaged\", action=\"got_engagement\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d3edc",
   "metadata": {},
   "source": [
    "6. The streams are shared with the students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "038ac21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag.add_transit(\"student_engaged\", \"stream_shared\", action=\"share_streams\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315ab6dd",
   "metadata": {},
   "source": [
    "7. The teacher asks the students to learn the function (in this case the sin).\n",
    "\n",
    "We set the input-output/descriptor stream to the stream hash of the teacher.\n",
    "We ask to learn for 2000 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "328e7567",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag.add_transit(\"stream_shared\", \"asked_learn\", action=\"ask_learn_gen\",\n",
    "               args={\"du_hash\": ag.name + \":recorded1\", \"yhat_hash\": ag.name + \":recorded1\", \"dhat_hash\": ag.name + \":recorded1\", \"ask_steps\": 2000})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7cb6e1",
   "metadata": {},
   "source": [
    "8. We end up the learning stage and we ask the students to generate the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d96bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag.add_transit(\"asked_learn\", \"done_learn\", action=\"done_learn_gen\")\n",
    "ag.add_transit(\"done_learn\", \"asked_gen\", action=\"ask_gen\", args={\"du_hash\": ag.name + \":record1\", \"ask_steps\": 2000})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2066fe",
   "metadata": {},
   "source": [
    "9. We end up the process and move to the end state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fd665ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag.add_transit(\"asked_gen\", \"finished\", action=\"done_gen\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ab616",
   "metadata": {},
   "source": [
    "At this point we can add the Teacher to the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c89cd539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding agent to environment\n",
    "env.add_agent(ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9435b72d",
   "metadata": {},
   "source": [
    "#### Now we can define a student agent\n",
    "\n",
    "We define the agent that will act the role of the Student in this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b88d7748",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = BasicAgent(\"Student\", model=DemoModel1(attributes=env.shared_attributes, lr=0.001, device=device), authority=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fa35f4",
   "metadata": {},
   "source": [
    "We now set its FSM...\n",
    "\n",
    "1. The student starts by acquiring the information of what streams are circulating in the enviroment.\n",
    "2. The student knows who are the other agents in the environment.\n",
    "3. The student is ready to engage with a teacher (notice now that we are looking for `min_auth` and `max_auth` equal to 1).\n",
    "4. After the engagement with a teacher, the student got information about the streams available for such teacher.\n",
    "5. The student is ready to learn the function, and starts the learning procedure.\n",
    "6. The student is ready to generate the function, and generate it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1387b177-2b5c-47c1-9079-0a554f370ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating student FSM\n",
    "ag.add_transit(\"init\", \"got_streams\", action=\"get_streams\")\n",
    "ag.add_transit(\"got_streams\", \"got_agents\", action=\"get_agents\")\n",
    "ag.add_transit(\"got_agents\", \"teacher_engaged\", action=\"get_engagement\", args={\"min_auth\": 1.0, \"max_auth\": 1.0})\n",
    "ag.add_transit(\"teacher_engaged\", \"got_teacher_streams\", action=\"get_streams\")\n",
    "ag.add_transit(\"got_teacher_streams\", \"learning\", action=\"do_learn_gen\")\n",
    "ag.add_transit(\"got_teacher_streams\", \"generated\", action=\"do_gen\")\n",
    "ag.add_transit(\"learning\", \"got_teacher_streams\", action=\"nop\")\n",
    "ag.add_transit(\"generated\", \"got_teacher_streams\", action=\"nop\")\n",
    "\n",
    "\n",
    "# adding agent to environment\n",
    "env.add_agent(ag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637575ee",
   "metadata": {},
   "source": [
    "Add a server to let the enviroment be accesible with a web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bebc4bd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Server' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m port \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2001\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mServer\u001b[49m(env\u001b[38;5;241m=\u001b[39menv, port\u001b[38;5;241m=\u001b[39mport)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Server' is not defined"
     ]
    }
   ],
   "source": [
    "port = 2001\n",
    "Server(env=env, port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bcd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THE ENVIROMENT\n",
    "env.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a7440-2ba5-4a11-b944-73ef60026c68",
   "metadata": {},
   "source": [
    "## Demo 2: learn and generate a playlist\n",
    "In this case, we are creating a Sandbox in which the Teacher has 2 different stream samples available for its Students.\\\n",
    "The lesson is structured as a playlist in which the Teacher provides the supervision, alternating the two signals.\\\n",
    "After 5 repetitions of each signal, the Student is aked to reproduce both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e30926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating environment\n",
    "# env = BasicEnvironment(\"env\", title=\"Demo Sandbox Playlist\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "env.remove_all_agents()\n",
    "env.behav.reset_state()\n",
    "\n",
    "# adding streams to the environment\n",
    "# env.add_stream(Stream.create(name=\"sin\", creator=env.name, stream=Sin(freq=0.06, phase=0.5, delta=0.1)))\n",
    "env.add_stream(Stream.create(name=\"square\", creator=env.name, stream=Square(freq=0.06, ampl=0.5, phase=0.5, delta=0.1)))\n",
    "\n",
    "# modeling behaviour of the environment\n",
    "# env.add_transit(\"init\", \"streams_enabled\", action=\"enable_all_streams\")\n",
    "# env.add_transit(\"streams_enabled\", \"streams_sent\", action=\"send_streams_to_all\")\n",
    "# env.add_transit(\"streams_sent\", \"ready\", action=\"send_agents_to_all\")\n",
    "\n",
    "# creating teacher agent\n",
    "ag = BasicAgent(\"Teacher\", model=EmptyModel(), authority=1.0)\n",
    "ag.add_transit(\"init\", \"got_streams\", action=\"get_streams\")\n",
    "ag.add_transit(\"got_streams\", \"got_agents\", action=\"get_agents\")\n",
    "ag.add_transit(\"got_agents\", \"recording1\", action=\"record\", args={\"stream_hash\": env.name + \":sin\", \"steps\": 500})\n",
    "ag.add_transit(\"recording1\", \"recording2\", action=\"record\", args={\"stream_hash\": env.name + \":square\", \"steps\": 500})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec9d20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2cfcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58495a-b5fc-4fd7-b568-c011153eb775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ag.add_transit(\"recording2\", \"playlist_ready\", action=\"set_pref_streams\",\n",
    "               args={\"stream_hashes\": [ag.name + \":recorded1\", ag.name + \":recorded2\"], \"repeat\": 6})\n",
    "ag.add_state_action(\"playlist_ready\", action=\"find_agent_to_engage\", args={\"min_auth\": 0.0, \"max_auth\": 0.0})\n",
    "ag.add_transit(\"playlist_ready\", \"student_found\", action=\"send_engagement\")\n",
    "ag.add_transit(\"student_found\", \"playlist_ready\", action=\"nop\")\n",
    "ag.add_transit(\"student_found\", \"student_engaged\", action=\"got_engagement\")\n",
    "ag.add_transit(\"student_engaged\", \"stream_shared\", action=\"share_streams\")\n",
    "ag.add_transit(\"stream_shared\", \"asked_learn\", action=\"ask_learn_gen\",\n",
    "               args={\"du_hash\": \"<playlist>\", \"yhat_hash\": \"<playlist>\", \"dhat_hash\": \"<playlist>\",\n",
    "                     \"ask_steps\": 500})\n",
    "ag.add_transit(\"asked_learn\", \"done_learn\", action=\"done_learn_gen\")\n",
    "ag.behav.add_state_action(\"done_learn\", action=\"next_pref_stream\")\n",
    "ag.behav.add_transit(\"done_learn\", \"stream_shared\", action=\"check_pref_stream\", args={\"what\": \"not_last_round\"})\n",
    "ag.behav.add_transit(\"done_learn\", \"ready_to_ask\", action=\"check_pref_stream\", args={\"what\": \"last_round\"})\n",
    "# add a final unsupervised generation for each signal\n",
    "ag.behav.add_transit(\"ready_to_ask\", \"asked_gen\", action=\"ask_gen\",\n",
    "                     args={\"du_hash\": \"<playlist>\",  \"dhat_hash\": \"<playlist>\", \"ask_steps\": 500})\n",
    "ag.behav.add_transit(\"asked_gen\", \"done_gen\", action=\"done_gen\")\n",
    "ag.behav.add_state_action(\"done_gen\", action=\"next_pref_stream\")\n",
    "ag.behav.add_transit(\"done_gen\", \"ready_to_ask\", action=\"check_pref_stream\", args={\"what\": \"not_first\"})\n",
    "ag.behav.add_transit(\"done_gen\", \"finished\", action=\"check_pref_stream\", args={\"what\": \"first\"})\n",
    "\n",
    "# adding agent to environment\n",
    "env.add_agent(ag)\n",
    "\n",
    "# creating student agent\n",
    "ag = BasicAgent(\"Student\", model=BasicModel(attributes=env.shared_attributes, lr=0.001, device=device),\n",
    "                authority=0.0)\n",
    "ag.add_transit(\"init\", \"got_streams\", action=\"get_streams\")\n",
    "ag.add_transit(\"got_streams\", \"got_agents\", action=\"get_agents\")\n",
    "ag.add_transit(\"got_agents\", \"teacher_engaged\", action=\"get_engagement\", args={\"min_auth\": 1.0, \"max_auth\": 1.0})\n",
    "ag.add_transit(\"teacher_engaged\", \"got_teacher_streams\", action=\"get_streams\")\n",
    "ag.add_transit(\"got_teacher_streams\", \"learning\", action=\"do_learn_gen_and_pred\")\n",
    "ag.add_transit(\"got_teacher_streams\", \"generated\", action=\"do_gen_and_pred\")\n",
    "ag.add_transit(\"learning\", \"got_teacher_streams\", action=\"nop\")\n",
    "ag.add_transit(\"generated\", \"got_teacher_streams\", action=\"nop\")\n",
    "\n",
    "# adding agent to environment\n",
    "env.add_agent(ag)\n",
    "\n",
    "# printing\n",
    "print(env)\n",
    "for ag in env.agents.values():\n",
    "    print(ag)\n",
    "\n",
    "# creating server\n",
    "Server(env=env)\n",
    "\n",
    "# running\n",
    "env.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad74bc4-8b9d-4c22-8f34-6bdf80731b55",
   "metadata": {},
   "source": [
    "## learn, generate playlist and descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92099017-09ab-41f8-b4ae-03cf68695d22",
   "metadata": {},
   "source": [
    "## old python code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb785d9-2f7b-41db-90fd-4a1f1efdfdbe",
   "metadata": {},
   "source": [
    "#### basic_model_gen4all_pre4all_gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bfeeff-0355-46a0-aea4-31064d174942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemoModel(Model):\n",
    "\n",
    "    def __init__(self, attributes: list[Attributes], lr: float = 0.0001, device: torch.device = torch.device(\"cpu\")):\n",
    "        \"\"\"Creates a model composed of a generator and a predictor.\"\"\"\n",
    "\n",
    "        # getting shape info from attributes (it is needed to build the generator/predictor)\n",
    "        assert len(attributes) == 2, \"Only two attributes are supported/expected (about y and d)\"\n",
    "        u_shape = attributes[0].shape\n",
    "        d_dim = attributes[1].shape.numel()\n",
    "        y_dim = attributes[0].shape.numel()\n",
    "\n",
    "        generator = GenCTBEInitStateBZeroInput(u_shape=u_shape, d_dim=d_dim, y_dim=y_dim, h_dim=500, delta=0.1,\n",
    "                                               local=False, cnu_memories=0)\n",
    "        predictor = PredRNN(y_dim=y_dim, d_dim=d_dim, h_dim=10)\n",
    "\n",
    "        # creating the model (superclass)\n",
    "        super(BasicModel, self).__init__(generator, predictor, attributes, device=device)\n",
    "\n",
    "        # extra stuff\n",
    "        self.optim = torch.optim.SGD(list(self.generator.parameters()) + list(self.predictor.parameters()), lr=lr)\n",
    "        self.loss_gen = torch.nn.functional.mse_loss\n",
    "        self.loss_pred = torch.nn.functional.mse_loss\n",
    "\n",
    "    def learn(self,\n",
    "              y: torch.Tensor | None, yhat: torch.Tensor | None,\n",
    "              d: torch.Tensor | None, dhat: torch.Tensor | None) \\\n",
    "            -> tuple[float, torch.Tensor | None, torch.Tensor | None, torch.Tensor | None, torch.Tensor | None]:\n",
    "        \"\"\"Learn from different types of data (some of them could be None).\"\"\"\n",
    "\n",
    "        # clean arguments, ensuring that what should be forced to None is actually forced to None\n",
    "        _, y, yhat, d, dhat = super().learn(y, yhat, d, dhat)  # it seems unuseful, but IT MUST be called!\n",
    "\n",
    "        # evaluating loss function\n",
    "        loss = ((self.loss_gen(y, yhat) if yhat is not None else 0.) +\n",
    "                (self.loss_pred(d, dhat) if dhat is not None else 0.))\n",
    "\n",
    "        # learning\n",
    "        self.optim.zero_grad()\n",
    "        loss_as_float = loss.item()\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "\n",
    "        return loss_as_float, y, yhat, d, dhat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96779592-dafa-45bb-9234-d2ba5e33b385",
   "metadata": {},
   "source": [
    "#### sandbox_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d3d38-245d-409d-9259-ac8a6a75da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from narnian.server import Server\n",
    "from narnian.streams import Stream\n",
    "from narnian.model import EmptyModel\n",
    "from basic.basic_agent import BasicAgent\n",
    "from basic.basic_model_gen4all_pred4all_gd import BasicModel\n",
    "from basic.basic_streams import Sin, Square\n",
    "from basic.basic_environment import BasicEnvironment\n",
    "\n",
    "# creating environment\n",
    "env = BasicEnvironment(\"env\", title=\"Sample Sandbox\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# adding streams to the environment\n",
    "env.add_stream(Stream.create(name=\"sin\", creator=env.name, stream=Sin(freq=0.06, phase=0.5, delta=0.1)))\n",
    "env.add_stream(Stream.create(name=\"square\", creator=env.name, stream=Square(freq=0.06, ampl=0.5, phase=0.5, delta=0.1)))\n",
    "\n",
    "# modeling behaviour of the environment\n",
    "env.add_transit(\"init\", \"streams_enabled\", action=\"enable_all_streams\")\n",
    "env.add_transit(\"streams_enabled\", \"streams_sent\", action=\"send_streams_to_all\")\n",
    "env.add_transit(\"streams_sent\", \"ready\", action=\"send_agents_to_all\")\n",
    "\n",
    "# creating teacher agent\n",
    "ag = BasicAgent(\"Teacher\", model=EmptyModel(), authority=1.0)\n",
    "ag.add_transit(\"init\", \"got_streams\", action=\"get_streams\")\n",
    "ag.add_transit(\"got_streams\", \"got_agents\", action=\"get_agents\")\n",
    "ag.add_transit(\"got_agents\", \"recording1\", action=\"record\",\n",
    "               args={\"stream_hash\": env.name + \":sin\", \"steps\": 500})\n",
    "ag.add_transit(\"recording1\", \"recording2\", action=\"record\",\n",
    "               args={\"stream_hash\": env.name + \":square\", \"steps\": 500})\n",
    "ag.add_transit(\"recording2\", \"playlist_ready\", action=\"set_pref_streams\",\n",
    "               args={\"stream_hashes\": [ag.name + \":recorded1\", ag.name + \":recorded2\"], \"repeat\": 1})\n",
    "ag.add_state_action(\"playlist_ready\", action=\"find_agent_to_engage\", args={\"min_auth\": 0.0, \"max_auth\": 0.0})\n",
    "ag.add_transit(\"playlist_ready\", \"student_found\", action=\"send_engagement\")\n",
    "ag.add_transit(\"student_found\", \"playlist_ready\", action=\"nop\")\n",
    "ag.add_transit(\"student_found\", \"student_engaged\", action=\"got_engagement\")\n",
    "ag.add_transit(\"student_engaged\", \"stream_shared\", action=\"share_streams\")\n",
    "ag.add_transit(\"stream_shared\", \"asked_learn\", action=\"ask_learn_gen_and_pred\",\n",
    "               args={\"du_hash\": \"<playlist>\", \"yhat_hash\": \"<playlist>\", \"dhat_hash\": \"<playlist>\",\n",
    "                     \"ask_steps\": 500})\n",
    "ag.add_transit(\"asked_learn\", \"done_learn\", action=\"done_learn_gen_and_pred\")\n",
    "ag.add_transit(\"done_learn\", \"asked_gen\", action=\"ask_gen_and_pred\",\n",
    "               args={\"du_hash\": \"<playlist>\", \"ask_steps\": 500})\n",
    "ag.add_transit(\"asked_gen\", \"done_gen\", action=\"done_gen_and_pred\")\n",
    "ag.add_state_action(\"done_gen\", action=\"eval\",\n",
    "                    args={\"stream_hash\": \"<playlist>\", \"what\": \"y\", \"how\": \"mse\", \"steps\": 500})\n",
    "ag.add_transit(\"done_gen\", \"stream_shared\", action=\"compare_eval\", args={\"cmp\": \">\", \"thres\": 0.05})\n",
    "ag.add_transit(\"done_gen\", \"good\", action=\"compare_eval\", args={\"cmp\": \"<=\", \"thres\": 0.05})\n",
    "ag.add_state_action(\"good\", action=\"next_pref_stream\")\n",
    "ag.add_transit(\"good\", \"stream_shared\", action=\"check_pref_stream\", args={\"what\": \"not_first\"})\n",
    "ag.add_transit(\"good\", \"finished\", action=\"check_pref_stream\", args={\"what\": \"first\"})\n",
    "\n",
    "# adding agent to environment\n",
    "env.add_agent(ag)\n",
    "\n",
    "# creating student agent\n",
    "ag = BasicAgent(\"Student\", model=BasicModel(attributes=env.shared_attributes, lr=0.001, device=device),\n",
    "                authority=0.0)\n",
    "ag.add_transit(\"init\", \"got_streams\", action=\"get_streams\")\n",
    "ag.add_transit(\"got_streams\", \"got_agents\", action=\"get_agents\")\n",
    "ag.add_transit(\"got_agents\", \"teacher_engaged\", action=\"get_engagement\", args={\"min_auth\": 1.0, \"max_auth\": 1.0})\n",
    "ag.add_transit(\"teacher_engaged\", \"got_teacher_streams\", action=\"get_streams\")\n",
    "ag.add_transit(\"got_teacher_streams\", \"learning\", action=\"do_learn_gen_and_pred\")\n",
    "ag.add_transit(\"got_teacher_streams\", \"generated\", action=\"do_gen_and_pred\")\n",
    "ag.add_transit(\"learning\", \"got_teacher_streams\", action=\"nop\")\n",
    "ag.add_transit(\"generated\", \"got_teacher_streams\", action=\"nop\")\n",
    "\n",
    "# adding agent to environment\n",
    "env.add_agent(ag)\n",
    "\n",
    "# printing\n",
    "print(env)\n",
    "for ag in env.agents.values():\n",
    "    print(ag)\n",
    "\n",
    "# creating server\n",
    "Server(env=env)\n",
    "\n",
    "# running\n",
    "env.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b0634-13e5-41b0-bfce-e1fdb555782c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "continuallm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
